
@article{das_loris:_2012,
	title = {{LORIS}: a web-based data management system for multi-center studies},
	volume = {5},
	issn = {1662-5196},
	doi = {10.3389/fninf.2011.00037},
	abstract = {Longitudinal Online Research and Imaging System (LORIS) is a modular and extensible web-based data management system that integrates all aspects of a multi-center study: from heterogeneous data acquisition (imaging, clinical, behavior, and genetics) to storage, processing, and ultimately dissemination. It provides a secure, user-friendly, and streamlined platform to automate the flow of clinical trials and complex multi-center studies. A subject-centric internal organization allows researchers to capture and subsequently extract all information, longitudinal or cross-sectional, from any subset of the study cohort. Extensive error-checking and quality control procedures, security, data management, data querying, and administrative functions provide LORIS with a triple capability (1) continuous project coordination and monitoring of data acquisition (2) data storage/cleaning/querying, (3) interface with arbitrary external data processing "pipelines." LORIS is a complete solution that has been thoroughly tested through a full 10 year life cycle of a multi-center longitudinal project and is now supporting numerous international neurodevelopment and neurodegeneration research projects.},
	number = {January},
	journal = {Frontiers in Neuroinformatics},
	author = {Das, Samir and Zijdenbos, Alex P. and Harlap, Jonathan and Vins, Dario and Evans, Alan C.},
	year = {2012},
	pmid = {22319489},
	note = {ISBN: 1662-5196},
	keywords = {neuroimaging, behavioral data, data querying, database, database, neuroimaging, longitudinal, multi-center, imaging data, longitudinal, mri, multi-center},
	pages = {1--11},
	file = {Das et al. - 2012 - LORIS a web-based data management system for multi-center studies.pdf:/Users/tclose/Zotero/storage/RZRPS2YU/Das et al. - 2012 - LORIS a web-based data management system for multi-center studies.pdf:application/pdf}
}

@inproceedings{abadi_tensorflow:_2016,
	address = {Savannah, GA, USA},
	title = {{TensorFlow}: {A} system for large-scale machine learning},
	booktitle={Proceedings of the 12th {USENIX} {S}ymposium on {O}perating {S}ystems {D}esign and {I}mplementation ({OSDI} ’16)},
	isbn = {978-1-931971-33-1},
	abstract = {TensorFlow is a machine learning system that operates at large scale and in heterogeneous environments. TensorFlow uses dataﬂow graphs to represent computation, shared state, and the operations that mutate that state. It maps the nodes of a dataﬂow graph across many machines in a cluster, and within a machine across multiple computational devices, including multicore CPUs, generalpurpose GPUs, and custom-designed ASICs known as Tensor Processing Units (TPUs). This architecture gives ﬂexibility to the application developer: whereas in previous “parameter server” designs the management of shared state is built into the system, TensorFlow enables developers to experiment with novel optimizations and training algorithms. TensorFlow supports a variety of applications, with a focus on training and inference on deep neural networks. Several Google services use TensorFlow in production, we have released it as an open-source project, and it has become widely used for machine learning research. In this paper, we describe the TensorFlow dataﬂow model and demonstrate the compelling performance that TensorFlow achieves for several real-world applications.},
	language = {en},
	author = {Abadi, Martın and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and others},
	month = nov,
	year = {2016},
	pages = {21},
	file = {Abadi et al. - TensorFlow A system for large-scale machine learn.pdf:/Users/tclose/Zotero/storage/D8388E67/Abadi et al. - TensorFlow A system for large-scale machine learn.pdf:application/pdf}
}

@article{achterberg_fastr:_2016,
	title = {Fastr: {A} {Workflow} {Engine} for {Advanced} {Data} {Flows} in {Medical} {Image} {Analysis}},
	volume = {3},
	issn = {2297-198X},
	shorttitle = {Fastr},
	doi = {10.3389/fict.2016.00015},
	abstract = {With the increasing number of datasets encountered in imaging studies, the increasing complexity of processing workflows, and a growing awareness for data stewardship, there is a need for managed, automated workflows. In this paper we introduce Fastr, an automated workflow engine with support for advanced data flows. Fastr has built-in data provenance for recording processing trails and ensuring reproducible results. The extensible plugin-based design allows the system to interface with virtually any image archive and processing infrastructure. This workflow engine is designed to consolidate quantitative imaging biomarker pipelines in order to enable easy application to new data.},
	language = {English},
	journal = {Frontiers in ICT},
	author = {Achterberg, Hakim C. and Koek, Marcel and Niessen, Wiro J.},
	year = {2016},
	keywords = {Data flow, data processing, Distributed Computing, pipeline, provenance, python, Reproducible Research, workflow},
	file = {Full Text PDF:/Users/tclose/Zotero/storage/BFL4Q6E7/Achterberg et al. - 2016 - Fastr A Workflow Engine for Advanced Data Flows i.pdf:application/pdf}
}

@misc{amstutz_common_2016,
	title = {Common {Workflow} {Language}, v1.0},
	doi = {10.6084/m9.figshare.3115156.v2},
	language = {English},
	author = {Amstutz, Peter and Crusoe, Michael R. and Tijanić, Nebojša and Chapman, Brad and Chilton, John and Heuer, Michael and Kartashov, Andrey and Leehr, Dan and Ménager, Hervé and Nedeljkovich, Maya and Scales, Matt and Soiland-Reyes, Stian and Stojanovic, Luka},
	month = jul,
	year = {2016},
	file = {Full Text PDF:/Users/tclose/Zotero/storage/9DZ9SH43/Amstutz et al. - 2016 - Common Workflow Language, v1.0.pdf:application/pdf;Snapshot:/Users/tclose/Zotero/storage/54SPF5RN/export.html:text/html}
}

@article{avants_reproducible_2011,
	title = {A reproducible evaluation of {ANTs} similarity metric performance in brain image registration},
	volume = {54},
	issn = {1053-8119},
	doi = {10.1016/j.neuroimage.2010.09.025},
	abstract = {The United States National Institutes of Health (NIH) commit significant support to open-source data and software resources in order to foment reproducibility in the biomedical imaging sciences. Here, we report and evaluate a recent product of this commitment: Advanced Neuroimaging Tools (ANTs), which is approaching its 2.0 release. The ANTs open source software library consists of a suite of state-of-the-art image registration, segmentation and template building tools for quantitative morphometric analysis. In this work, we use ANTs to quantify, for the first time, the impact of similarity metrics on the affine and deformable components of a template-based normalization study. We detail the ANTs implementation of three similarity metrics: squared intensity difference, a new and faster cross-correlation, and voxel-wise mutual information. We then use two-fold cross-validation to compare their performance on openly available, manually labeled, T1-weighted MRI brain image data of 40 subjects (UCLA's LPBA40 dataset). We report evaluation results on cortical and whole brain labels for both the affine and deformable components of the registration. Results indicate that the best ANTs methods are competitive with existing brain extraction results (Jaccard=0.958) and cortical labeling approaches. Mutual information affine mapping combined with cross-correlation diffeomorphic mapping gave the best cortical labeling results (Jaccard=0.669±0.022). Furthermore, our two-fold cross-validation allows us to quantify the similarity of templates derived from different subgroups. Our open code, data and evaluation scripts set performance benchmark parameters for this state-of-the-art toolkit. This is the first study to use a consistent transformation framework to provide a reproducible evaluation of the isolated effect of the similarity metric on optimal template construction and brain labeling.},
	number = {3},
	journal = {NeuroImage},
	author = {Avants, Brian B. and Tustison, Nicholas J. and Song, Gang and Cook, Philip A. and Klein, Arno and Gee, James C.},
	month = feb,
	year = {2011},
	pages = {2033--2044},
	file = {Accepted Version:/Users/tclose/Zotero/storage/35N89C6S/Avants et al. - 2011 - A reproducible evaluation of ANTs similarity metri.pdf:application/pdf;ScienceDirect Snapshot:/Users/tclose/Zotero/storage/CMFKH65G/S1053811910012061.html:text/html}
}

@article{book_neuroinformatics_2013,
	title = {Neuroinformatics {Database} ({NiDB})--a modular, portable database for the storage, analysis, and sharing of neuroimaging data},
	volume = {11},
	issn = {1559-0089},
	doi = {10.1007/s12021-013-9194-1},
	abstract = {We present a modular, high performance, open-source database system that incorporates popular neuroimaging database features with novel peer-to-peer sharing, and a simple installation. An increasing number of imaging centers have created a massive amount of neuroimaging data since fMRI became popular more than 20 years ago, with much of that data unshared. The Neuroinformatics Database (NiDB) provides a stable platform to store and manipulate neuroimaging data and addresses several of the impediments to data sharing presented by the INCF Task Force on Neuroimaging Datasharing, including 1) motivation to share data, 2) technical issues, and 3) standards development. NiDB solves these problems by 1) minimizing PHI use, providing a cost effective simple locally stored platform, 2) storing and associating all data (including genome) with a subject and creating a peer-to-peer sharing model, and 3) defining a sample, normalized definition of a data storage structure that is used in NiDB. NiDB not only simplifies the local storage and analysis of neuroimaging data, but also enables simple sharing of raw data and analysis methods, which may encourage further sharing.},
	language = {eng},
	number = {4},
	journal = {Neuroinformatics},
	author = {Book, Gregory A. and Anderson, Beth M. and Stevens, Michael C. and Glahn, David C. and Assaf, Michal and Pearlson, Godfrey D.},
	month = oct,
	year = {2013},
	pmid = {23912507},
	pmcid = {PMC3864015},
	keywords = {Brain, Database Management Systems, Humans, Image Processing, Computer-Assisted, Information Dissemination, Information Storage and Retrieval, Neuroimaging},
	pages = {495--505},
	file = {Accepted Version:/Users/tclose/Zotero/storage/9HPBEAZX/Book et al. - 2013 - Neuroinformatics Database (NiDB)--a modular, porta.pdf:application/pdf}
}

@article{cox_afni:_1996,
	title = {{AFNI}: software for analysis and visualization of functional magnetic resonance neuroimages},
	volume = {29},
	issn = {0010-4809},
	shorttitle = {{AFNI}},
	abstract = {A package of computer programs for analysis and visualization of three-dimensional human brain functional magnetic resonance imaging (FMRI) results is described. The software can color overlay neural activation maps onto higher resolution anatomical scans. Slices in each cardinal plane can be viewed simultaneously. Manual placement of markers on anatomical landmarks allows transformation of anatomical and functional scans into stereotaxic (Talairach-Tournoux) coordinates. The techniques for automatically generating transformed functional data sets from manually labeled anatomical data sets are described. Facilities are provided for several types of statistical analyses of multiple 3D functional data sets. The programs are written in ANSI C and Motif 1.2 to run on Unix workstations.},
	language = {eng},
	number = {3},
	journal = {Computers and Biomedical Research, an International Journal},
	author = {Cox, R. W.},
	month = jun,
	year = {1996},
	pmid = {8812068},
	keywords = {Brain, Computer Systems, Data Display, Humans, Image Processing, Computer-Assisted, Magnetic Resonance Imaging, Programming Languages, Software, Stereotaxic Techniques, User-Computer Interface},
	pages = {162--173}
}

@article{cusack_automatic_2015,
	title = {Automatic analysis (aa): efficient neuroimaging workflows and parallel processing using {Matlab} and {XML}},
	volume = {8},
	issn = {1662-5196},
	shorttitle = {Automatic analysis (aa)},
	doi = {10.3389/fninf.2014.00090},
	abstract = {Recent years have seen neuroimaging data becoming richer, with larger cohorts of participants, a greater variety of acquisition techniques, and increasingly complex analyses. These advances have made data analysis pipelines complex to set up and run (increasing the risk of human error) and time consuming to execute (restricting what analyses are attempted). Here we present an open-source framework, automatic analysis (aa), to address these concerns. Human efficiency is increased by making code modular and reusable, and managing its execution with a processing engine that tracks what has been completed and what needs to be (re)done. Analysis is accelerated by optional parallel processing of independent tasks on cluster or cloud computing resources. A pipeline comprises a series of modules that each perform a specific task. The processing engine keeps track of the data, calculating a map of upstream and downstream dependencies for each module. Existing modules are available for many analysis tasks, such as SPM-based fMRI preprocessing, individual and group level statistics, voxel-based morphometry, tractography, and multi-voxel pattern analyses (MVPA). However, aa also allows for full customization, and encourages efficient management of code: new modules may be written with only a small code overhead. aa has been used by more than 50 researchers in hundreds of neuroimaging studies comprising thousands of subjects. It has been found to be robust, fast and efficient, for simple single subject studies up to multimodal pipelines on hundreds of subjects. It is attractive to both novice and experienced users. aa can reduce the amount of time neuroimaging laboratories spend performing analyses and reduce errors, expanding the range of scientific questions it is practical to address.},
	language = {English},
	journal = {Frontiers in Neuroinformatics},
	author = {Cusack, Rhodri and Vicente-Grabovetsky, Alejandro and Mitchell, Daniel J. and Wild, Conor J. and Auer, Tibor and Linke, Annika C. and Peelle, Jonathan E.},
	year = {2015},
	keywords = {Diffusion Magnetic Resonance Imaging, fMRI methods, MRI, Software, workflow},
	file = {Full Text PDF:/Users/tclose/Zotero/storage/MZQWYGBL/Cusack et al. - 2015 - Automatic analysis (aa) efficient neuroimaging wo.pdf:application/pdf}
}

@article{gorgolewski_brain_2016,
	title = {The brain imaging data structure, a format for organizing and describing outputs of neuroimaging experiments},
	volume = {3},
	copyright = {2016 Nature Publishing Group},
	issn = {2052-4463},
	doi = {10.1038/sdata.2016.44},
	abstract = {The development of magnetic resonance imaging (MRI) techniques has defined modern neuroimaging. Since its inception, tens of thousands of studies using techniques such as functional MRI and diffusion weighted imaging have allowed for the non-invasive study of the brain. Despite the fact that MRI is routinely used to obtain data for neuroscience research, there has been no widely adopted standard for organizing and describing the data collected in an imaging experiment. This renders sharing and reusing data (within or between labs) difficult if not impossible and unnecessarily complicates the application of automatic pipelines and quality assurance protocols. To solve this problem, we have developed the Brain Imaging Data Structure (BIDS), a standard for organizing and describing MRI datasets. The BIDS standard uses file formats compatible with existing software, unifies the majority of practices already common in the field, and captures the metadata necessary for most common data processing operations.},
	language = {en},
	journal = {Scientific Data},
	author = {Gorgolewski, Krzysztof J. and Auer, Tibor and Calhoun, Vince D. and Craddock, R. Cameron and Das, Samir and Duff, Eugene P. and Flandin, Guillaume and Ghosh, Satrajit S. and Glatard, Tristan and Halchenko, Yaroslav O. and Handwerker, Daniel A. and Hanke, Michael and Keator, David and Li, Xiangrui and Michael, Zachary and Maumet, Camille and Nichols, B. Nolan and Nichols, Thomas E. and Pellman, John and Poline, Jean-Baptiste and Rokem, Ariel and Schaefer, Gunnar and Sochat, Vanessa and Triplett, William and Turner, Jessica A. and Varoquaux, Gaël and Poldrack, Russell A.},
	month = jun,
	year = {2016},
	pages = {160044},
	file = {Full Text PDF:/Users/tclose/Zotero/storage/GJ88ESAF/Gorgolewski et al. - 2016 - The brain imaging data structure, a format for org.pdf:application/pdf;Snapshot:/Users/tclose/Zotero/storage/JHBEKQ7F/sdata201644.html:text/html}
}

@article{goscinski_multi-modal_2014,
	title = {The multi-modal {Australian} {ScienceS} {Imaging} and {Visualization} {Environment} ({MASSIVE}) high performance computing infrastructure: applications in neuroscience and neuroinformatics research},
	volume = {8},
	issn = {1662-5196},
	shorttitle = {The multi-modal {Australian} {ScienceS} {Imaging} and {Visualization} {Environment} ({MASSIVE}) high performance computing infrastructure},
	doi = {10.3389/fninf.2014.00030},
	abstract = {The Multi-modal Australian ScienceS Imaging and Visualisation Environment (MASSIVE) is a national imaging and visualisation facility established by Monash University, the Australian Synchrotron, the Commonwealth Scientific Industrial Research Organisation (CSIRO), and the Victorian Partnership for Advanced Computing (VPAC), with funding from the National Computational Infrastructure and the Victorian Government. The MASSIVE facility provides hardware, software and expertise to drive research in the biomedical sciences, particularly advanced brain imaging research using synchrotron x-ray and infrared imaging, functional and structural magnetic resonance imaging (MRI), x-ray computer tomography (CT), electron microscopy and optical microscopy. The development of MASSIVE has been based on best practice in system integration methodologies, frameworks, and architectures. The facility has: (i) integrated multiple different neuroimaging analysis software components, (ii) enabled cross-platform and cross-modality integration of neuroinformatics tools, and (iii) brought together neuroimaging databases and analysis workflows. MASSIVE is now operational as a nationally distributed and integrated facility for neuroinfomatics and brain imaging research.},
	language = {English},
	journal = {Frontiers in Neuroinformatics},
	author = {Goscinski, Wojtek James and McIntosh, Paul and Felzmann, Ulrich Claus and Maksimenko, Anton and Hall, Christopher John and Gureyev, Timur and Thompson, Darren and Janke, Andrew and Galloway, Graham and Killeen, Neil E. B. and Raniga, Parnesh and Kaluza, Owen and Ng, Amanda and Poudel, Govinda and Barnes, David and Nguyen, Toan and Bonnington, Paul and Egan, Gary F.},
	year = {2014},
	keywords = {CT reconstruction, data management, Digital atlasing of the mouse brain, GPU computing in neuroinformatics, High performance computing, Huntington’s disease, Instrument integration, Neuroinformatics in the Cloud, neuroinformatics infrastructure, Quantitative susceptibility mapping},
	file = {Full Text PDF:/Users/tclose/Zotero/storage/F5QZKNIZ/Goscinski et al. - 2014 - The multi-modal Australian ScienceS Imaging and Vi.pdf:application/pdf}
}

@misc{yaroslav_halchenko_datalad/datalad_2018,
	title = {datalad/datalad 0.10.3.1},
	abstract = {Keep scientific data under control with git and git-annex},
	publisher = {Zenodo},
	author = {Yaroslav Halchenko and Michael Hanke and Benjamin Poldrack and Kyle Meyer and Debanjum and Gergana Alteva and jason gors and Dave MacFarlane and Christian Olaf Häusler and Taylor Olson and Alex Waite and Alejandro de la Vega and Anisha Keshavan and bhanuprasad14 and yetanothertestuser and yarikoptic-private and Vicky C Lau and tstoeter and Nell Hardcastle and Matteo Visconti di Oleggio Castello and Kusti Skytén and Jorrit Poelen and Horea Christian and Feilong Ma},
	month = sep,
	year = {2018},
	doi = {10.5281/zenodo.1418485},
	file = {Zenodo Snapshot:/Users/tclose/Zotero/storage/JEJUZMWR/1418485.html:text/html}
}

@article{kennedy_neuroimaging_2018,
	title = {Neuroimaging {Neuroinformatics}: {Sample} {Size} and {Other} {Evolutionary} {Topics}},
	volume = {16},
	issn = {1559-0089},
	shorttitle = {Neuroimaging {Neuroinformatics}},
	doi = {10.1007/s12021-018-9379-8},
	language = {en},
	number = {2},
	journal = {Neuroinformatics},
	author = {Kennedy, David N.},
	month = apr,
	year = {2018},
	pages = {149--150},
	file = {Springer Full Text PDF:/Users/tclose/Zotero/storage/L43GHLSE/Kennedy - 2018 - Neuroimaging Neuroinformatics Sample Size and Oth.pdf:application/pdf}
}

@article{marcus_extensible_2007,
	title = {The extensible neuroimaging archive toolkit},
	volume = {5},
	issn = {1559-0089},
	doi = {10.1385/NI:5:1:11},
	abstract = {The Extensible Neuroimaging Archive Toolkit (XNAT) is a software platform designed to facilitate common management and productivity tasks for neuroimaging and associated data. In particular, XNAT enables qualitycontrol procedures and provides secure access to and storage of data. XNAT follows a threetiered architecture that includes a data archive, user interface, and middleware engine. Data can be entered into the archive as XML or through data entry forms. Newly added data are stored in a virtual quarantine until an authorized user has validated it. XNAT subsequently maintains a history profile to track all changes made to the managed data. User access to the archive is provided by a secure web application. The web application provides a number of quality control and productivity features, including data entry forms, data-type-specific searches, searches that combine across data types, detailed reports, and listings of experimental data, upload/download tools, access to standard laboratory workflows, and administration and security tools. XNAT also includes an online image viewer that supports a number of common neuroimaging formats, including DICOM and Analyze. The viewer can be extended to support additional formats and to generate custom displays. By managing data with XNAT, laboratories are prepared to better maintain the long-term integrity of their data, to explore emergent relations across data types, and to share their data with the broader neuroimaging community.},
	language = {en},
	number = {1},
	journal = {Neuroinformatics},
	author = {Marcus, Daniel S. and Olsen, Timothy R. and Ramaratnam, Mohana and Buckner, Randy L.},
	month = mar,
	year = {2007},
	keywords = {Data sharing, database, genetics, informatics, metadata, neuroinformatics, open, quality control, source, workflow, XML schema},
	pages = {11--33}
}

@article{gorgolewski_nipype:_2011,
	title = {Nipype: a flexible, lightweight and extensible neuroimaging data processing framework in python},
	volume = {5},
	issn = {1662-5196},
	shorttitle = {Nipype},
	doi = {10.3389/fninf.2011.00013},
	abstract = {Current neuroimaging software offer users an incredible opportunity to analyze their data in different ways, with different underlying assumptions. Several sophisticated software packages (e.g., AFNI, BrainVoyager, FSL, FreeSurfer, Nipy, R, SPM) are used to process and analyze large and often diverse (highly multi-dimensional) data. However, this heterogeneous collection of specialized applications creates several issues that hinder replicable, efficient, and optimal use of neuroimaging analysis approaches: (1) No uniform access to neuroimaging analysis software and usage information; (2) No framework for comparative algorithm development and dissemination; (3) Personnel turnover in laboratories often limits methodological continuity and training new personnel takes time; (4) Neuroimaging software packages do not address computational efficiency; and (5) Methods sections in journal articles are inadequate for reproducing results. To address these issues, we present Nipype (Neuroimaging in Python: Pipelines and Interfaces; http://nipy.org/nipype), an open-source, community-developed, software package, and scriptable library. Nipype solves the issues by providing Interfaces to existing neuroimaging software with uniform usage semantics and by facilitating interaction between these packages using Workflows. Nipype provides an environment that encourages interactive exploration of algorithms, eases the design of Workflows within and between packages, allows rapid comparative development of algorithms and reduces the learning curve necessary to use different packages. Nipype supports both local and remote execution on multi-core machines and clusters, without additional scripting. Nipype is Berkeley Software Distribution licensed, allowing anyone unrestricted usage. An open, community-driven development philosophy allows the software to quickly adapt and address the varied needs of the evolving neuroimaging community, especially in the context of increasing demand for reproducible research.},
	language = {eng},
	journal = {Frontiers in Neuroinformatics},
	author = {Gorgolewski, Krzysztof and Burns, Christopher D. and Madison, Cindee and Clark, Dav and Halchenko, Yaroslav O. and Waskom, Michael L. and Ghosh, Satrajit S.},
	year = {2011},
	pmid = {21897815},
	pmcid = {PMC3159964},
	keywords = {data processing, neuroimaging, pipeline, Python, reproducible research, workflow},
	pages = {13},
	file = {Full Text:/Users/tclose/Zotero/storage/U4BLYHNI/Gorgolewski et al. - 2011 - Nipype a flexible, lightweight and extensible neu.pdf:application/pdf}
}

@inbook{raymond_cathedral_1999,
	title = {The {Cathedral} and the {Bazaar}},
	booktitle = {The {Cathedral} and the {Bazaar}},
	isbn = {1-56592-724-9},
	language = {en},
	publisher = {O'Reilly Media},
	author = {Raymond, Eric S.},
	year = {1999},
	pages = {30},
	file = {Snapshot:/Users/tclose/Zotero/storage/DYKDYZF9/9780596001087.html:text/html}
}

@article{scott_coins:_2011,
	title = {{COINS}: {An} {Innovative} {Informatics} and {Neuroimaging} {Tool} {Suite} {Built} for {Large} {Heterogeneous} {Datasets}},
	volume = {5},
	issn = {1662-5196},
	shorttitle = {{COINS}},
	doi = {10.3389/fninf.2011.00033},
	abstract = {The availability of well-characterized neuroimaging data with large numbers of subjects, especially for clinical populations, is critical to advancing our understanding of the healthy and diseased brain. Such data enables questions to be answered in a much more generalizable manner and also has the potential to yield solutions derived from novel methods that were conceived after the original studies' implementation. Though there is currently growing interest in data sharing, the neuroimaging community has been struggling for years with how to best encourage sharing data across brain imaging studies. With the advent of studies that are much more consistent across sites (e.g., resting functional magnetic resonance imaging, diffusion tensor imaging, and structural imaging) the potential of pooling data across studies continues to gain momentum. At the mind research network, we have developed the collaborative informatics and neuroimaging suite (COINS; http://coins.mrn.org) to provide researchers with an information system based on an open-source model that includes web-based tools to manage studies, subjects, imaging, clinical data, and other assessments. The system currently hosts data from nine institutions, over 300 studies, over 14,000 subjects, and over 19,000 MRI, MEG, and EEG scan sessions in addition to more than 180,000 clinical assessments. In this paper we provide a description of COINS with comparison to a valuable and popular system known as XNAT. Although there are many similarities between COINS and other electronic data management systems, the differences that may concern researchers in the context of multi-site, multi-organizational data sharing environments with intuitive ease of use and PHI security are emphasized as important attributes.},
	language = {eng},
	journal = {Frontiers in Neuroinformatics},
	author = {Scott, Adam and Courtney, Will and Wood, Dylan and de la Garza, Raul and Lane, Susan and King, Margaret and Wang, Runtang and Roberts, Jody and Turner, Jessica A. and Calhoun, Vince D.},
	year = {2011},
	pmid = {22275896},
	pmcid = {PMC3250631},
	keywords = {brain imaging, database, neuroinformatics},
	pages = {33},
	file = {Full Text:/Users/tclose/Zotero/storage/YED73YZ2/Scott et al. - 2011 - COINS An Innovative Informatics and Neuroimaging .pdf:application/pdf}
}

@article{smith_advances_2004,
	title = {Advances in functional and structural {MR} image analysis and implementation as {FSL}},
	volume = {23 Suppl 1},
	issn = {1053-8119},
	doi = {10.1016/j.neuroimage.2004.07.051},
	abstract = {The techniques available for the interrogation and analysis of neuroimaging data have a large influence in determining the flexibility, sensitivity, and scope of neuroimaging experiments. The development of such methodologies has allowed investigators to address scientific questions that could not previously be answered and, as such, has become an important research area in its own right. In this paper, we present a review of the research carried out by the Analysis Group at the Oxford Centre for Functional MRI of the Brain (FMRIB). This research has focussed on the development of new methodologies for the analysis of both structural and functional magnetic resonance imaging data. The majority of the research laid out in this paper has been implemented as freely available software tools within FMRIB's Software Library (FSL).},
	language = {eng},
	journal = {NeuroImage},
	author = {Smith, Stephen M. and Jenkinson, Mark and Woolrich, Mark W. and Beckmann, Christian F. and Behrens, Timothy E. J. and Johansen-Berg, Heidi and Bannister, Peter R. and De Luca, Marilena and Drobnjak, Ivana and Flitney, David E. and Niazy, Rami K. and Saunders, James and Vickers, John and Zhang, Yongyue and De Stefano, Nicola and Brady, J. Michael and Matthews, Paul M.},
	year = {2004},
	pmid = {15501092},
	keywords = {Bayes Theorem, Brain, Databases, Factual, Humans, Image Processing, Computer-Assisted, Magnetic Resonance Imaging, Models, Neurological, Models, Statistical, Software},
	pages = {S208--219},
	file = {Submitted Version:/Users/tclose/Zotero/storage/3QH9XNKS/Smith et al. - 2004 - Advances in functional and structural MR image ana.pdf:application/pdf}
}

@article{sudlow_uk_2015,
	title = {{UK} {Biobank}: {An} {Open} {Access} {Resource} for {Identifying} the {Causes} of a {Wide} {Range} of {Complex} {Diseases} of {Middle} and {Old} {Age}},
	volume = {12},
	issn = {1549-1277},
	shorttitle = {{UK} {Biobank}},
	doi = {10.1371/journal.pmed.1001779},
	abstract = {Cathie Sudlow and colleagues describe the UK Biobank, a large population-based prospective study, established to allow investigation of the genetic and non-genetic determinants of the diseases of middle and old age.},
	number = {3},
	journal = {PLoS Medicine},
	author = {Sudlow, Cathie and Gallacher, John and Allen, Naomi and Beral, Valerie and Burton, Paul and Danesh, John and Downey, Paul and Elliott, Paul and Green, Jane and Landray, Martin and Liu, Bette and Matthews, Paul and Ong, Giok and Pell, Jill and Silman, Alan and Young, Alan and Sprosen, Tim and Peakman, Tim and Collins, Rory},
	month = mar,
	year = {2015},
	pmid = {25826379},
	pmcid = {PMC4380465},
	file = {PubMed Central Full Text PDF:/Users/tclose/Zotero/storage/2G2QKCR3/Sudlow et al. - 2015 - UK Biobank An Open Access Resource for Identifyin.pdf:application/pdf}
}

@article{tournier_mrtrix:_2012,
	title = {{MRtrix}: {Diffusion} tractography in crossing fiber regions},
	volume = {22},
	copyright = {Copyright © 2011 Wiley Periodicals, Inc.},
	issn = {1098-1098},
	shorttitle = {{MRtrix}},
	doi = {10.1002/ima.22005},
	abstract = {In recent years, diffusion-weighted magnetic resonance imaging has attracted considerable attention due to its unique potential to delineate the white matter pathways of the brain. However, methodologies currently available and in common use among neuroscientists and clinicians are typically based on the diffusion tensor model, which has comprehensively been shown to be inadequate to characterize diffusion in brain white matter. This is due to the fact that it is only capable of resolving a single fiber orientation per voxel, causing incorrect fiber orientations, and hence pathways, to be estimated through these voxels. Given that the proportion of affected voxels has been recently estimated at 90\%, this is a serious limitation. Furthermore, most implementations use simple “deterministic” streamlines tracking algorithms, which have now been superseded by “probabilistic” approaches. In this study, we present a robust set of tools to perform tractography, using fiber orientations estimated using the validated constrained spherical deconvolution method, coupled with a probabilistic streamlines tracking algorithm. This methodology is shown to provide superior delineations of a number of known white matter tracts, in a manner robust to crossing fiber effects. These tools have been compiled into a software package, called MRtrix, which has been made freely available for use by the scientific community. © 2012 Wiley Periodicals, Inc. Int J Imaging Syst Technol, 22, 53–66, 2012},
	language = {en},
	number = {1},
	journal = {International Journal of Imaging Systems and Technology},
	author = {Tournier, J.-Donald and Calamante, Fernando and Connelly, Alan},
	month = mar,
	year = {2012},
	keywords = {crossing fibers, diffusion MRI, fiber tracking, tractography},
	pages = {53--66},
	file = {Snapshot:/Users/tclose/Zotero/storage/HEK4TX57/ima.html:text/html}
}

@article{thompson_enigma_2014,
	title = {The {ENIGMA} {Consortium}: large-scale collaborative analyses of neuroimaging and genetic data},
	volume = {8},
	issn = {1931-7565},
	shorttitle = {The {ENIGMA} {Consortium}},
	doi = {10.1007/s11682-013-9269-5},
	abstract = {The Enhancing NeuroImaging Genetics through Meta-Analysis (ENIGMA) Consortium is a collaborative network of researchers working together on a range of large-scale studies that integrate data from 70 institutions worldwide. Organized into Working Groups that tackle questions in neuroscience, genetics, and medicine, ENIGMA studies have analyzed neuroimaging data from over 12,826 subjects. In addition, data from 12,171 individuals were provided by the CHARGE consortium for replication of findings, in a total of 24,997 subjects. By meta-analyzing results from many sites, ENIGMA has detected factors that affect the brain that no individual site could detect on its own, and that require larger numbers of subjects than any individual neuroimaging study has currently collected. ENIGMA's first project was a genome-wide association study identifying common variants in the genome associated with hippocampal volume or intracranial volume. Continuing work is exploring genetic associations with subcortical volumes (ENIGMA2) and white matter microstructure (ENIGMA-DTI). Working groups also focus on understanding how schizophrenia, bipolar illness, major depression and attention deficit/hyperactivity disorder (ADHD) affect the brain. We review the current progress of the ENIGMA Consortium, along with challenges and unexpected discoveries made on the way.},
	language = {eng},
	number = {2},
	journal = {Brain Imaging and Behavior},
	author = {Thompson, Paul M. and Stein, Jason L. and Medland, Sarah E. and Hibar, Derrek P. and Vasquez, Alejandro Arias and Renteria, Miguel E. and Toro, Roberto and Jahanshad, Neda and Schumann, Gunter and Franke, Barbara and others},
	month = jun,
	year = {2014},
	pmid = {24399358},
	pmcid = {PMC4008818},
	keywords = {Brain Mapping, Cooperative Behavior, Genome-Wide Association Study, Humans, Meta-Analysis as Topic, Neuroimaging},
	pages = {153--182},
	file = {Full Text:/Users/tclose/Zotero/storage/2M389SNK/Thompson et al. - 2014 - The ENIGMA Consortium large-scale collaborative a.pdf:application/pdf}
}

@article{van_essen_human_2012,
	title = {The {Human} {Connectome} {Project}: a data acquisition perspective},
	volume = {62},
	issn = {1095-9572},
	shorttitle = {The {Human} {Connectome} {Project}},
	doi = {10.1016/j.neuroimage.2012.02.018},
	abstract = {The Human Connectome Project (HCP) is an ambitious 5-year effort to characterize brain connectivity and function and their variability in healthy adults. This review summarizes the data acquisition plans being implemented by a consortium of HCP investigators who will study a population of 1200 subjects (twins and their non-twin siblings) using multiple imaging modalities along with extensive behavioral and genetic data. The imaging modalities will include diffusion imaging (dMRI), resting-state fMRI (R-fMRI), task-evoked fMRI (T-fMRI), T1- and T2-weighted MRI for structural and myelin mapping, plus combined magnetoencephalography and electroencephalography (MEG/EEG). Given the importance of obtaining the best possible data quality, we discuss the efforts underway during the first two years of the grant (Phase I) to refine and optimize many aspects of HCP data acquisition, including a new 7T scanner, a customized 3T scanner, and improved MR pulse sequences.},
	language = {eng},
	number = {4},
	journal = {NeuroImage},
	author = {Van Essen, D. C. and Ugurbil, K. and Auerbach, E. and Barch, D. and Behrens, T. E. J. and Bucholz, R. and Chang, A. and Chen, L. and Corbetta, M. and Curtiss, S. W. and Della Penna, S. and Feinberg, D. and Glasser, M. F. and Harel, N. and Heath, A. C. and Larson-Prior, L. and Marcus, D. and Michalareas, G. and Moeller, S. and Oostenveld, R. and Petersen, S. E. and Prior, F. and Schlaggar, B. L. and Smith, S. M. and Snyder, A. Z. and Xu, J. and Yacoub, E. and {WU-Minn HCP Consortium}},
	month = oct,
	year = {2012},
	pmid = {22366334},
	pmcid = {PMC3606888},
	keywords = {Brain, Brain Mapping, Connectome, Humans},
	pages = {2222--2231},
	file = {Accepted Version:/Users/tclose/Zotero/storage/HKTATH72/Van Essen et al. - 2012 - The Human Connectome Project a data acquisition p.pdf:application/pdf}
}

@article{ward_combining_2018,
	title = {Combining images and anatomical knowledge to improve automated vein segmentation in {MRI}},
	volume = {165},
	issn = {1053-8119},
	doi = {10.1016/j.neuroimage.2017.10.049},
	abstract = {Purpose
To improve the accuracy of automated vein segmentation by combining susceptibility-weighted images (SWI), quantitative susceptibility maps (QSM), and a vein atlas to produce a resultant image called a composite vein image (CV image).
Method
An atlas was constructed in common space from manually traced MRI images from ten volunteers. The composite vein image was derived for each subject as a weighted sum of three inputs; an SWI image, a QSM image and the vein atlas. The weights for each input and each anatomical location, called template priors, were derived by assessing the accuracy of each input over an independent data set. The accuracy of vein segmentations derived automatically from each of the CV image, SWI, and QSM image sets was assessed by comparison with manual tracings. Three different automated vein segmentation techniques were used, and ten performance metrics evaluated.
Results
Vein segmentations using the CV image were comprehensively better than those derived from SWI or QSM images (mean Cohen's d = 1.1). Sixty permutations of performance metric, benchmark image, and automated segmentation technique were evaluated. Vein identification improvements that were both large and significant (Cohen's d {\textgreater} 0.80, p {\textless} 0.05) were found in 77\% of the permutations, compared to no improvement in 5\%.
Conclusion
The accuracy of automated vein segmentations derived from the composite vein image was overwhelmingly superior to segmentations derived from SWI or QSM alone.},
	journal = {NeuroImage},
	author = {Ward, Phillip G. D. and Ferris, Nicholas J. and Raniga, Parnesh and Dowe, David L. and Ng, Amanda C. L. and Barnes, David G. and Egan, Gary F.},
	month = jan,
	year = {2018},
	keywords = {Cerebral vasculature, MRI, QSM, SWI, Vein atlas, Vein segmentation},
	pages = {294--305},
	file = {ScienceDirect Snapshot:/Users/tclose/Zotero/storage/S8H3SYGZ/S1053811917308765.html:text/html}
}

@book{yacoub_pattern-oriented_2004,
	title = {Pattern-oriented {Analysis} and {Design}: {Composing} {Patterns} to {Design} {Software} {Systems}},
	isbn = {978-0-201-77640-9},
	shorttitle = {Pattern-oriented {Analysis} and {Design}},
	abstract = {Software experts agree: the most difficult aspect of building software is not coding; it is the decisions the designer makes in the early stages. Those decisions live with the system for the rest of its lifetime. Good designs beget good software. Bad designs beget trouble. Designers are faced with a tough question: how do they know whether their designs are good or bad? Design patterns can provide valid judgment criteria for software designers. While a great deal of effort has been devoted to discovering new design patterns, very little effort has been spent on developing a process for "gluing" or "composing" design patterns to better develop software applications. This book specifically addresses this need, and explains the Pattern-Oriented Analysis and Design (POAD) methodology to utilize design patterns. The methodology is practical, logical, and above all, proven! Four case studies and numerous examples show how to apply POAD, and a useful glossary and bibliography make the text a lasting reference for better software design.},
	language = {en},
	publisher = {Addison-Wesley Professional},
	author = {Yacoub, Sherif M. and Ammar, Hany Hussein},
	year = {2004},
	note = {Google-Books-ID: dbU4ggCbqd4C},
	keywords = {Computers / Software Development \& Engineering / General}
}

@article{esteban_fmriprep:_2018,
	title = {{FMRIPrep}: a robust preprocessing pipeline for functional {MRI}},
	doi = {10.1101/306951},
	abstract = {Preprocessing of functional MRI (fMRI) involves numerous steps to clean and standardize data before statistical analysis. Generally, researchers create ad hoc preprocessing workflows for each new dataset, building upon a large inventory of tools available for each step. The complexity of these workflows has snowballed with rapid advances in MR data acquisition and image processing techniques. We introduce fMRIPrep, an analysis-agnostic tool that addresses the challenge of robust and reproducible preprocessing for task-based and resting fMRI data. FMRIPrep automatically adapts a best-in-breed workflow to the idiosyncrasies of virtually any dataset, ensuring high-quality preprocessing with no manual intervention. By introducing visual assessment checkpoints into an iterative integration framework for software-testing, we show that fMRIPrep robustly produces high-quality results on a diverse fMRI data collection comprising participants from 54 different studies in the OpenfMRI repository. We review the distinctive features of fMRIPrep in a qualitative comparison to other preprocessing workflows. We demonstrate that fMRIPrep achieves higher spatial accuracy as it introduces less uncontrolled spatial smoothness than commonly used preprocessing tools. FMRIPrep has the potential to transform fMRI research by equipping neuroscientists with a high-quality, robust, easy-to-use and transparent preprocessing workflow which can help ensure the validity of inference and the interpretability of their results.},
	journal = {bioRxiv},
	author = {Esteban, Oscar and Markiewicz, Christopher and Blair, Ross W and Moodie, Craig and Isik, Ayse Ilkay and Erramuzpe Aliaga, Asier and Kent, James and Goncalves, Mathias and DuPre, Elizabeth and Snyder, Madeleine and Oya, Hiroyuki and Ghosh, Satrajit and Wright, Jessey and Durnez, Joke and Poldrack, Russell and Gorgolewski, Krzysztof Jacek},
	month = jan,
	year = {2018}
}

@inproceedings{ward_vein_2017,
	title = {Vein segmentation using shape-based {Markov} {Random} {Fields}},
	booktitle = {Biomedical {Imaging} ({ISBI} 2017), 2017 {IEEE} 14th {International} {Symposium} on},
	publisher = {IEEE},
	author = {Ward, Phillip GD and Ferris, Nicholas J and Raniga, Parnesh and Ng, Amanda CL and Barnes, David G and Dowe, David L and Egan, Gary F},
	year = {2017},
	pages = {1133--1136}
}

@book{friston_statistical_2007,
	title = {Statistical {Parametric} {Mapping}},
	isbn = {978-0-12-372560-8},
	language = {en},
	publisher = {Elsevier},
	author = {Friston, Karl},
	year = {2007},
	doi = {10.1016/B978-0-12-372560-8.X5000-1}
}

@inproceedings{furlani_modules:_1991,
	title = {Modules: {Providing} a flexible user environment},
	booktitle = {Proceedings of the fifth large installation systems administration conference ({LISA} {V})},
	author = {Furlani, John L},
	year = {1991},
	pages = {141--152}
}

@book{moore_professional_2008,
	title = {Professional {Python} {Frameworks}: {Web} 2.0 {Programming} with {Django} and {Turbogears}},
	publisher = {John Wiley \& Sons},
	author = {Moore, Dana and Budd, Raymond and Wright, William},
	year = {2008}
}

@book{paszke_pytorch:_2017,
	title = {Pytorch: {Tensors} and dynamic neural networks in python with strong gpu acceleration},
	author = {Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory},
	year = {2017}
}

@inproceedings{tournier_improved_2010,
	title = {Improved probabilistic streamlines tractography by 2nd order integration over fibre orientation distributions},
	volume = {18},
	booktitle = {Proceedings of the international society for magnetic resonance in medicine},
	author = {Tournier, J Donald and Calamante, Fernando and Connelly, Alan},
	year = {2010},
	pages = {1670}
}

@book{white_hadoop:_2012,
	title = {Hadoop: {The} definitive guide},
	publisher = {O'Reilly Media, Inc.},
	author = {White, Tom},
	year = {2012}
}

@inproceedings{schreiber_using_2018,
	address = {Singapore, Singapore},
	title = {Using a {Multi}-{Petaflop} {Supercomputer} for {Pushing} {Neuroimaging} {Analytics} to the {Next} {Level}},
	booktitle = {Proceedings of {Organisation} for {Human} {Brain} {Mapping} 2018},
	author = {Schreiber, Jan and Hoffstaedter, Felix and Deepu, Rajalekshmi and Orth, Boris and Lippert, Thomas and Amunts, Katrin and Eickhoff, Simon and Caspers, Svenja},
	month = jun,
	year = {2018}
}
@inproceedings{maumet:inserm-01886089,
  TITLE = {{Tools and standards to make neuroimaging derived data reusable}},
  AUTHOR = {Maumet, Camille},
  URL = {http://www.hal.inserm.fr/inserm-01886089},
  BOOKTITLE = {{Neuroinformatics 2018}},
  ADDRESS = {Montreal, Canada},
  YEAR = {2018},
  MONTH = Aug,
  PDF = {http://www.hal.inserm.fr/inserm-01886089/file/Maumet_INCF_Neuroinformatics_2018.pdf},
  HAL_ID = {inserm-01886089},
  HAL_VERSION = {v1},
}

@inproceedings{grabner_symmetric_2006,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Symmetric {Atlasing} and {Model} {Based} {Segmentation}: {An} {Application} to the {Hippocampus} in {Older} {Adults}},
	isbn = {978-3-540-44728-3},
	shorttitle = {Symmetric {Atlasing} and {Model} {Based} {Segmentation}},
	language = {en},
	booktitle = {Medical {Image} {Computing} and {Computer}-{Assisted} {Intervention} – {MICCAI} 2006},
	publisher = {Springer Berlin Heidelberg},
	author = {Grabner, Günther and Janke, Andrew L. and Budge, Marc M. and Smith, David and Pruessner, Jens and Collins, D. Louis},
	editor = {Larsen, Rasmus and Nielsen, Mads and Sporring, Jon},
	year = {2006},
	keywords = {Average Scaling Factor, Computerize Brain Atlas, Individual Patient Anatomy, Registration Result, Standard Deviation Image},
	pages = {58--66},
	file = {Springer Full Text PDF:/Users/tclose/Zotero/storage/T5LS2FFC/Grabner et al. - 2006 - Symmetric Atlasing and Model Based Segmentation A.pdf:application/pdf}
}
@inproceedings{yoo_slurm:_2003,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{SLURM}: {Simple} {Linux} {Utility} for {Resource} {Management}},
	isbn = {978-3-540-39727-4},
	shorttitle = {{SLURM}},
	abstract = {A new cluster resource management system called Simple Linux Utility Resource Management (SLURM) is described in this paper. SLURM, initially developed for large Linux clusters at the Lawrence Livermore National Laboratory (LLNL), is a simple cluster manager that can scale to thousands of processors. SLURM is designed to be flexible and fault-tolerant and can be ported to other clusters of different size and architecture with minimal effort. We are certain that SLURM will benefit both users and system architects by providing them with a simple, robust, and highly scalable parallel job execution environment for their cluster system.},
	language = {en},
	booktitle = {Job {Scheduling} {Strategies} for {Parallel} {Processing}},
	publisher = {Springer Berlin Heidelberg},
	author = {Yoo, Andy B. and Jette, Morris A. and Grondona, Mark},
	editor = {Feitelson, Dror and Rudolph, Larry and Schwiegelshohn, Uwe},
	year = {2003},
	keywords = {Exit Status, Lawrence Livermore National Laboratory, Message Authentication Code, Remote Execution, Resource Management System},
	pages = {44--60}
}

@article{wilkinson_fair_2016,
	title = {The {FAIR} {Guiding} {Principles} for scientific data management and stewardship},
	volume = {3},
	issn = {2052-4463},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4792175/},
	doi = {10.1038/sdata.2016.18},
	abstract = {There is an urgent need to improve the infrastructure supporting the reuse of scholarly data. A diverse set of stakeholders—representing academia, industry, funding agencies, and scholarly publishers—have come together to design and jointly endorse a concise and measureable set of principles that we refer to as the FAIR Data Principles. The intent is that these may act as a guideline for those wishing to enhance the reusability of their data holdings. Distinct from peer initiatives that focus on the human scholar, the FAIR Principles put specific emphasis on enhancing the ability of machines to automatically find and use the data, in addition to supporting its reuse by individuals. This Comment is the first formal publication of the FAIR Principles, and includes the rationale behind them, and some exemplar implementations in the community.},
	urldate = {2019-03-18},
	journal = {Scientific Data},
	author = {Wilkinson, Mark D. and Dumontier, Michel and Aalbersberg, IJsbrand Jan and Appleton, Gabrielle and Axton, Myles and Baak, Arie and Blomberg, Niklas and Boiten, Jan-Willem and da Silva Santos, Luiz Bonino and Bourne, Philip E. and Bouwman, Jildau and Brookes, Anthony J. and Clark, Tim and Crosas, Mercè and Dillo, Ingrid and Dumon, Olivier and Edmunds, Scott and Evelo, Chris T. and Finkers, Richard and Gonzalez-Beltran, Alejandra and Gray, Alasdair J.G. and Groth, Paul and Goble, Carole and Grethe, Jeffrey S. and Heringa, Jaap and ’t Hoen, Peter A.C and Hooft, Rob and Kuhn, Tobias and Kok, Ruben and Kok, Joost and Lusher, Scott J. and Martone, Maryann E. and Mons, Albert and Packer, Abel L. and Persson, Bengt and Rocca-Serra, Philippe and Roos, Marco and van Schaik, Rene and Sansone, Susanna-Assunta and Schultes, Erik and Sengstag, Thierry and Slater, Ted and Strawn, George and Swertz, Morris A. and Thompson, Mark and van der Lei, Johan and van Mulligen, Erik and Velterop, Jan and Waagmeester, Andra and Wittenburg, Peter and Wolstencroft, Katherine and Zhao, Jun and Mons, Barend},
	month = mar,
	year = {2016},
	pmid = {26978244},
	pmcid = {PMC4792175},
	file = {PubMed Central Full Text PDF:/Users/tclose/Zotero/storage/ANVJGVWL/Wilkinson et al. - 2016 - The FAIR Guiding Principles for scientific data ma.pdf:application/pdf}
}